{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding via SeqVec\n",
    "*Implementation by Klaus Baruffi, Fabio Pfaehler* <br>\n",
    "*SeqVec embedder by mheinziger* ([Repository](https://github.com/mheinzinger/SeqVec), [Fork by Rostlab](https://github.com/Rostlab/SeqVec))\n",
    "\n",
    "Useful Resources:\n",
    "- [Comparison of different embedders](https://www.mdpi.com/1422-0067/24/4/3775)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setting up a conda environment and dependencies\n",
    "1) install anaconda\n",
    "2) deactivate the base env \n",
    "    - $conda deactivate\n",
    "3) create and activate python 3.8.18 conda env\n",
    "    - $conda create --name myenv python=3.8.18\n",
    "    - $conda activate myenv\n",
    "5) $pip install seqvec\n",
    "6) Install other dependencies (which for what: see 'Error encounter' notifications below the particular notebook cells)\n",
    "    - $pip install overrides==3.1.0\n",
    "    - $pip install Bio\n",
    "    - *also check pyproject.toml in the SeqVec Github repository*\n",
    "    - *Eventually you need to restart your jupyter kernel after certain changes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Choose input fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test file for download (tiny_sampled.fasta)\n",
    "# !wget http://data.bioembeddings.com/public/embeddings/notebooks/custom_data/tiny_sampled.fasta --output-document fasta_files/tiny_sampled.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"fasta_files/tiny_sampled.fasta\"\n",
    "# filepath = \"fasta_files/VOG00024.faa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate Embeddings\n",
    "\n",
    "SeqVec is a pretrained model trained on large databases (Uniprot/Uniref50). The model consists of two files: An options.json and a Weights.hdf5 file which can be downloaded and unziped using the next two code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download SeqVec model (ELMo model trained on UniRef50) as zip folder\n",
    "# !wget https://rostlab.org/~deepppi/seqvec.zip --output-document seqvec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unzip and store model files in a folder called 'SV_model' in your working directory (assuming you have unzip installed: $sudo apt-get install unzip)\n",
    "# !unzip seqvec.zip -d . \n",
    "# !mkdir -p SV_model \n",
    "# !mv uniref50_v2/* SV_model/\n",
    "# !rm -r uniref50_v2/ seqvec.zip # remove empty folders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "from pathlib import Path\n",
    "\n",
    "model_dir = Path('SV_model/')\n",
    "weights = model_dir / 'weights.hdf5'\n",
    "options = model_dir / 'options.json'\n",
    "embedder = ElmoEmbedder(options,weights, cuda_device=-1) # cuda_device=-1 for CPU, 0 for GPU (faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Encounter:**\n",
    "- issue with allennlp\n",
    "    1) allennlp should be version 0.9.0 and overrides 3.1.0\n",
    "    2) Eventually you need numpy 1.21\n",
    "- CUDA capability of GPU not compatible with current PyTorch installation\n",
    "    - For Nvidea Geforce RTX 3050 Laptop GPU with CUDA capability sm_86:\n",
    "        1) $conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge\n",
    "        2) Check out PyTorch versions that match your GPU ([https://pytorch.org/](https://pytorch.org/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "\n",
    "# Extract sequences from fasta file and store them as a list\n",
    "sequences = []\n",
    "for record in SeqIO.parse(filepath, \"fasta\"):\n",
    "    sequences.append(list(record.seq))\n",
    "\n",
    "# Sort the sequences in order to enhance performance\n",
    "sequences.sort(key=len) \n",
    "\n",
    "# Generate amino acid level embedding\n",
    "aa_embd = embedder.embed_sentences(sequences) # returns: List-of-Lists with shape [3,L,1024]\n",
    "aa_embd = list(aa_embd) # turn generator into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "    \n",
    "# Get 1024-dimensional embedding for per-protein predictions:\n",
    "protein_embd_SV = torch.tensor(aa_embd).sum(dim=0).mean(dim=0) # Vector with shape [1024]\n",
    "\n",
    "# Get 1024-dimensional embedding for per-residue predictions:\n",
    "residue_embd_SV = torch.tensor(aa_embd).sum(dim=0) # Tensor with shape [L,1024]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
