{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bio Embeddings for Shallow Learners\n",
    "1) Choose a VOG\n",
    "2) Choose and create bio embedding algorithm: SeqVec, ProtTrans \n",
    "    - Input: VOG specific .fasta file\n",
    "    - Store sequences as objects in a list\n",
    "    - Create embedder object and then a protein- or aminoacid-embedding\n",
    "    - Output: Vector of sequences represented/embedded as points in a multidimensional (feature-) space (vector of vectors). The embeddings harbor a constant number of features, in contrast to the previous state, where protein sequences had different lengths. So the VOG has now this embedding matrix as a profile.\n",
    "\n",
    "**Links:**\n",
    "- [SeqVec Repository](https://github.com/Rostlab/SeqVec)\n",
    "    - [SeqVec Source-Code](https://github.com/Rostlab/SeqVec/blob/master/seqvec/seqvec.py)\n",
    "- [ProtTrans Respository](https://github.com/agemagician/ProtTrans)\n",
    "- [Embedder Benchmark Paper](https://www.mdpi.com/1422-0067/24/4/3775)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## o) Install and Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seqvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from Bio import SeqIO\n",
    "from bio_embeddings.embed import ProtTransBertBFDEmbedder\n",
    "from bio_embeddings.embed.seqvec_embedder import SeqVecEmbedder\n",
    "from bio_embeddings.project import tsne_reduce\n",
    "from bio_embeddings.visualize import render_3D_scatter_plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## o) Generate Embedding: SeqVec\n",
    "### Input: .fasta file | Output: array of embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-09 13:28:25,182 Running on the CPU\n",
      "2024-02-09 13:28:25,182 Total number of sequences: 12\n",
      "2024-02-09 13:28:25,182 Loading the model\n",
      "2024-02-09 13:28:25,182 Initializing ELMo.\n",
      "0 _____________________\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/bin/seqvec\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/site-packages/seqvec/seqvec.py\", line 417, in main\n",
      "    save_from_generator(emb_path, per_prot, embeddings_generator)\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/site-packages/seqvec/seqvec.py\", line 252, in save_from_generator\n",
      "    for sequence_id, embedding in the_generator:\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/site-packages/seqvec/seqvec.py\", line 201, in get_embeddings\n",
      "    model = get_elmo_model(model_dir, cpu)\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/site-packages/seqvec/seqvec.py\", line 44, in get_elmo_model\n",
      "    return ElmoEmbedder(\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/site-packages/allennlp/commands/elmo.py\", line 175, in __init__\n",
      "    self.elmo_bilm = _ElmoBiLm(options_file, weight_file)\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/site-packages/allennlp/modules/elmo.py\", line 526, in __init__\n",
      "    self._token_embedder = _ElmoCharacterEncoder(options_file, weight_file, requires_grad=requires_grad)\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/site-packages/allennlp/modules/elmo.py\", line 306, in __init__\n",
      "    self._options = json.load(fin)\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/json/__init__.py\", line 293, in load\n",
      "    return loads(fp.read(),\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/dinglemittens/anaconda3/envs/SPEnv38/lib/python3.8/json/decoder.py\", line 356, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "filepath = \"BE_testing/tiny_sampled.fasta\"\n",
    "# # !seqvec -i $filepath -o embeddings.npz\n",
    "!seqvec -i $filepath -o embeddings.npz --split-char ' ' --id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "Error encounter: <br>\n",
    "- json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0) <br>\n",
    "- The seqvec command has an optional parameter --model, for choosing a pretrained ELMo model (as 2 files: weights.hdf5 and options.json). <br>\n",
    "- If the parameter is not set, the command will download the files for the default model automatically. <br>\n",
    "- Apparently the .json file is empty (?). The options file also starts with an initial line, typcial for html files and not json files.<br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## o) Generate Embedding: Bio-Embeddings Module\n",
    "see <embed_fasta_sequences.ipynb>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create (download) testing fasta file (tiny_sampled.fasta)\n",
    "# !wget http://data.bioembeddings.com/public/embeddings/notebooks/custom_data/tiny_sampled.fasta --output-document BE_testing/tiny_sampled.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Member-ID     Identifier\t\tLength\t    Sequence\n",
      "\n",
      "Protein 1     A0A2I1HIX6                  129       MYNILFSIIENSWFIDLIKTLQLEYDSPSRQVLSGILLEPKISHVNICIINELSADNNFTIAIDEHLSNVIEEIINKVGAVAIVSDNSLNIAAAHKIITNNYPNIINMQCITHCVNLINIFIGEKLIFQ\n",
      "Protein 2     MiniChange                  129       MYNILFSIIENSWFIDLIKTLQLEYDSPSQQVLSGILLEPKISHVNICIINELSADNNFTIAIDEHLSNVIEEIINKVGAVAIVSDNSLNIAAAHKIITNNYPNIINMQCITHCVNLINIFIGEKLIFQ\n",
      "Protein 3     Q95021                      46        PQGIEVVVLLFCLKIRYRDRIFLLRGNHETPSVNKVYFKCIVSFNF\n",
      ". . .\n",
      "Protein 11    A0A2D0S5G3                  439       MAVSRMRSAWAALCIAVLVMSGSAEGASLVTLKAANTEPSYSYDLTMDVTNRIYSDSLLNPYSDDYNMMYEEVSTALYSVYGCPTCDTRTFYQGVTAMTFSNKAGSVVVQATIMFSSRHTNAVVIKFLFLSAISDKNEINGLKINPDFIQVIQGSAPAPMSTSHPTTTPSPTPTTTTPTPTTSTTTPSPTPTTTTPTPTTTITICDTIPPSTPNTTPTTTTPTPTTTITICDTIPPSTPTTTPSPTITTAPSTTPTSILTTTPPITPPTASEIGFTPIPTTTPITFPSTAPSVTPTTSPPISSTTNPIIPIQYDATSSATPPPIPPTTTQTTTTPVTPFTSPTTTPTTIISTTTSFTPNTTLPTISTTSQTTTTITLTTTPGTITTTVPISSIPLPNPQPQAIPVPQPEPVPEPLPDPFPLPIDEPLPLILPDAEQQKH\n",
      "Protein 12    UPI0009EC8762               159       MRRCSRPSWRQGCNAGGARETPADDLRPDECRGSMGAGPDRSHRTGLLRAGDRAGRRAGRAVSVVSGRPKALPDGTAPYRSLGPFGPSDLPSGLLRRHRLAEGVWGLLRLQAGRVVFVWEDGSEEREELTAPAELVVPPQVPHHLEVEGDFSIALTFHR\n",
      "Protein 13    QHN70907.1                  1584      MFLFFCAATILCLWVNSGGAVVVSNETLVFCEPVSYPYSLQVLRSFSQRVNLRTKRAVIIDAWSFAYQISTNSLNVNGWYVNFTSPLGWSYPNGKPFGIVLGSDAMMRASQSIFTYDVISYVGQRPNLDCQINDLVNGGLKNWYSTVRVDNCGNYPCHGGGKPGCSIGQPYMANGVCTRVLSTTQSPGIQYEIYSGQDYAVYQITPYTQYTVTMPSGTSGYCQQTPLYVECGSWTPYRVHTYGCDKVTQSCKYTISSDWVVAFKSKITAVTLPSDLKVPVVQKVTKRLGVTSPDYFWLIKQAYQYLSQATISPNYALFSALSNSLYQQSLVLTDLCYGSPFFMARECYNNALYLPDAVFTTLFSILFSWDYQVNYPVNNVLQSNETFLQLPTTGYLGQTVSQGRMLNLFKDAIVFLDFYDTKFYRTNDGPGGDIFAVVVKQAPVIAYSAFRIEQQTGDYLAVKCNGVTQATLAPHSSRVVLLARHMSMWSIAAANSTTIYCPIYTLTQFGSLDISTSWYFHTLAQPSGPIQQVSMPLLSTAAAGVYMYPMVEHWVTLLTQTQDVYQPSMFNMGVNKSVTLTTQLQAYAQVYTAWFLSILYTRLPESRRLTLGAQLTPFIQALLSFRQADIDATDVDTVARYNVLSLMWGRKYAAVSYNQLPEWSYPLFKGGVGDSMWFRKEISCTTQNPSTSSHFPFIAGYLDFLDYKYIPKYKDVACPTTMVTPTLLQVYETPQLFVIIVQCVSTTYSWYPGLRNPHTIYRSYKLGTICILVPYSSPTSVYSSFGFFFQSALTIPIVQTTDDILPGCVGFVQDSVFTPCHPSGCPVRNSYDNYIICPGSSASNYTLRNYHRTTIPVTNVPIDEVPLQLEIPTVSLTSYELKQSESVLLQDIEGGIVVDHNTGSIWYPDGQAYDVSFYVSVIIRYAPPKLELPSTLANFTSCLDYICFGNQQCRGEAQTFCTSMDYFEQVFNKSLTSLIIALQDLHYVLKLVLPETTLELTEDTRRRRRAVDEFSDTISLLSESFERFMSPASQAYMANMMWWDEAFDGISLPQRTGSILSRTPSLSSTSSWRSYSSRTPLISNVKTPKTTFNVKLSMPKLPKASTLSTIGSVLSSGLSIASLGLSIFSIIEDRRVTELTQQQIMALENQITILTDYTEKNFKEIQSFLNTLGQQVQDFSQQVTLSLQQLFNGLEQITQQLDKSIYYVMAVQQYATYMSSFVNQLNELSQAVYKTQDMYITCIHSLQSGVLSPNCITPAQMFHLYQVAKNLSGECQPIFSEREISRFYSLPLVTDAMVHNDTYWFSWSIPITCSNILGSVYKVQPGYIVNPHHPTSLQYDVPTHVVTSNAGALIFDEHYCDRYNQVYLCTKSAFDLAESSYLTMLYSNQTDNSSLTFHPEPRPVPCVYLSASALYCYYSDECHQCVIAVGNCTNRTVTYENYTYSIMDPQCRGFDQVTISSPIAIGADFTALPSRPPLPLHLSYVNVTFNVTLPNGVNWTDLVLDYSFKDKVYEISKNITQLHEQILQVSNWASGWFQRLRDFLYGLIPAWITWLTLGFSLFSILISGVNIILFFEMNGKVKKS\n"
     ]
    }
   ],
   "source": [
    "# Extract sequences from fasta file and store them as a list\n",
    "filepath = \"BE_testing/tiny_sampled.fasta\"\n",
    "# filepath = \"BE_testing/VOG1_trial2/VOG00001.faa\"\n",
    "sequences = []\n",
    "for record in SeqIO.parse(filepath, \"fasta\"):\n",
    "    sequences.append(record)\n",
    "\n",
    "# Sanity-check (First 3 and last 3 sequences)\n",
    "print(f\"Member-ID     Identifier\\t\\tLength\\t    Sequence\\n\")\n",
    "for i,s in enumerate(sequences[:3]): # s:SeqIO-object\n",
    "    print(f\"Protein {i+1:<6}{(s.id):<28}{len(s.seq):<10}{s.seq}\") # :<6 for proper output alignment\n",
    "print(\". . .\")\n",
    "for i,s in enumerate(sequences[-3:], start=len(sequences)-2):\n",
    "    print(f\"Protein {i+1:<6}{(s.id):<28}{len(s.seq):<10}{s.seq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embedder Object\n",
    "# embedder = ProtTransBertBFDEmbedder()\n",
    "embedder = SeqVecEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Amino Acid Level Embedding (takes quiet some time)\n",
    "aa_embeddings = embedder.embed_many([str(s.seq) for s in sequences])\n",
    "# `embed_many` returns a generator.\n",
    "# We want to keep both RAW embeddings and reduced embeddings in memory.\n",
    "# To do so, we simply turn the generator into a list!\n",
    "# (this will start embedding the sequences!)\n",
    "# Needs certain amount of GPU RAM, if not sufficient CPU is used (slower)\n",
    "aa_embeddings = list(aa_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm_86 pytorch compatibility issue:\n",
    "- wrong pytorch version prevented using the GPU for the following embedding computation.\n",
    "- solved: conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge\n",
    "\n",
    "About SeqVec:\n",
    "- https://github.com/Rostlab/SeqVec/blob/master/README.md : \"All results built upon the embeddings gained from the new tool SeqVec neither explicitly nor implicitly using evolutionary information. Nevertheless, it improved over some methods using such information. Where the lightning-fast HHblits needed on average about two minutes to generate the evolutionary information for a target protein, SeqVec created the vector representation on average in 0.03 seconds.\"\n",
    "- Directory: - \\\\wsl.localhost\\Ubuntu\\home\\dinglemittens\\anaconda3\\envs\\SPEnv38\\lib\\python3.8\\site-packages\\bio_embeddings\\embed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trouble with Speed:\n",
    "- Managed to install the proper pytorch version such that the embedder does not have to use the CPU, but it still took (too?) long. Interrupted after 77min for SeqVecEmbedder(). Interruption after 40 min for ProtTransBertBFDEmbedder().\n",
    "- For the tiny_sampled.fasta file which harbors 12 sequences of a total length of 3682 aminoacids, the embedding run took 43 seconds, which are ~5k aminoacids per minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the number of dimensions of an array\n",
    "def dimension_number(array):\n",
    "    dim_num = 0\n",
    "    sublist = array\n",
    "    while isinstance(sublist, (np.ndarray, list)):\n",
    "        dim_num += 1\n",
    "        sublist = sublist[0]\n",
    "    return dim_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amino acid level embeddings object shape (SeqVec):\n",
      "( 12 | 3 | variable | 1024 )\n",
      "( no. of sequences | NN layers | sequence length | embedding dimensions)\n"
     ]
    }
   ],
   "source": [
    "# Print Shape of Amino Acid Level Embedding\n",
    "if dimension_number(aa_embeddings) == 4:\n",
    "      print(f\"Amino acid level embeddings object shape (SeqVec):\")\n",
    "      print(f\"( {len(aa_embeddings)} | {len(aa_embeddings[0])} | variable | {len(aa_embeddings[0][0][0])} )\")\n",
    "      print(\"( no. of sequences | NN layers | sequence length | embedding dimensions)\")\n",
    "elif dimension_number(aa_embeddings) == 3:\n",
    "      print(f\"Amino acid level embeddings object shape (ProtTrans):\")\n",
    "      print(f\"( {len(aa_embeddings)} | variable | {len(aa_embeddings[0][0][0])} )\")\n",
    "      print(\"( no. of sequences | sequence length | embedding dimensions)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Protein Level Embedding\n",
    "protein_embeddings = [embedder.reduce_per_protein(e) for e in aa_embeddings]\n",
    "# mean of amino acid level vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein level embeddings-object shape:\n",
      "o) 2 dimensional list of <len(sequences)> embedding vectors with 1024 entries\n",
      "o) 1st D (number of sequences)\t12\n",
      "o) 2nd D (embedding dimensions)\t1024 (constant)\n",
      "Shape: (12, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Print Shape of Protein Level Embedding\n",
    "print(\"protein level embeddings-object shape:\")\n",
    "print(\"o) 2 dimensional list of <len(sequences)> embedding vectors with 1024 entries\")\n",
    "print(f\"o) 1st D (number of sequences)\\t{len(protein_embeddings)}\")\n",
    "print(f\"o) 2nd D (embedding dimensions)\\t{len(protein_embeddings[0])} (constant)\")\n",
    "print(f\"Shape: {np.shape(protein_embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Summary of Embedding Shapes:  Sequence | AA Level Embedding | Protein Level Embedding\n",
    "print(\"Member ID\\tAA Level Embedding\\tProtein Level Embedding\")\n",
    "for i, (per_amino_acid, per_protein) in enumerate(zip(aa_embeddings[:3], protein_embeddings[:3])):\n",
    "    print(f\"Protein {i+1}\\t{per_amino_acid.shape}\\t\\t{per_protein.shape}\")\n",
    "print(\". . .\")\n",
    "for i, (per_amino_acid, per_protein) in enumerate(zip(aa_embeddings[-3:], protein_embeddings[-3:]), start=len(aa_embeddings)-2):\n",
    "    print(f\"Protein {i+1}\\t{per_amino_acid.shape}\\t\\t{per_protein.shape}\")\n",
    "print(\"\\nAA embedding should have shape (seq-length, embedding-dimensions), Protein embedding (embedding-dimensions,)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## o) Projecting high dimensional embedding space to a 3D space\n",
    "see <project_visualize_pipeline_embeddings.ipynb> (Bio-embeddings GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure tsne options\n",
    "options = {\n",
    "    'perplexity': 3, # Low perplexity values (e.g., 3) cause t-SNE to focus more on preserving the local structure of the data (high, e.g. 30).\n",
    "    'n_iter': 500 # number of iterations for the tsne algorithm\n",
    "}\n",
    "\n",
    "# Apply TSNE Projection \n",
    "projected_p_embedding = tsne_reduce(protein_embeddings, **options) # list\n",
    "\n",
    "# Display Projected Embedding (from 1024 dimensional (Protein Level) vectors to 3 dimensional coordinate vectors)\n",
    "print(f\"\\nShape of projected/dimensionality-reduced protein level embedding: {projected_p_embedding.shape}\\n\")\n",
    "for i,embedding in enumerate(projected_p_embedding[:3]): # first 3\n",
    "    print(f\"Protein {i+1}\\t{embedding}\")\n",
    "print(\". . .\")\n",
    "for i,embedding in enumerate(projected_p_embedding[-3:]): # last 3\n",
    "    print(f\"Protein {i+len(projected_p_embedding)-2}\\t{embedding}\")\n",
    "print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## o) Visualization of the Data\n",
    "see <project_visualize_pipeline_embeddings.ipynb> (Bio-embeddings GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D scatter plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Extract x, y, and z coordinates from the data\n",
    "x = projected_p_embedding[:, 0]\n",
    "y = projected_p_embedding[:, 1]\n",
    "z = projected_p_embedding[:, 2]\n",
    "\n",
    "# Plot the points\n",
    "ax.scatter(x, y, z)\n",
    "\n",
    "# Set labels for each axis\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Via plotly.express\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    projected_p_embedding, x=0, y=1, z=2,\n",
    "    labels={'0': 'label 1', '1': 'label 2', '2': 'label 3'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw code from ChatGTP\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = px.data.iris()\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "components = pca.fit_transform(X)\n",
    "\n",
    "total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    components, x=0, y=1, z=2, color=df['species'],\n",
    "    title=f'Total Explained Variance: {total_var:.2f}%',\n",
    "    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPEnv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
